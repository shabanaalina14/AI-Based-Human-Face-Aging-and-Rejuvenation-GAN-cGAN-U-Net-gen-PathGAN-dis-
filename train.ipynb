{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacd14b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaba\\AppData\\Local\\Temp\\ipykernel_29540\\3739871055.py:21: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # ‚úÖ Mixed precision scaler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23708 images for training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/741 [00:00<?, ?it/s]C:\\Users\\shaba\\AppData\\Local\\Temp\\ipykernel_29540\\3739871055.py:85: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # ‚úÖ mixed precision\n",
      "c:\\Users\\shaba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\shaba\\AppData\\Local\\Temp\\ipykernel_29540\\3739871055.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [2:46:37<00:00, 13.49s/it, D_loss=0.0003, G_loss=9.7669]     \n",
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [1:27:02<00:00,  7.05s/it, D_loss=0.0001, G_loss=10.8563]    \n",
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [13:35:55<00:00, 66.07s/it, D_loss=0.0000, G_loss=12.0497]        \n",
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [23:17<00:00,  1.89s/it, D_loss=0.0000, G_loss=12.2667]\n",
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [14:52<00:00,  1.20s/it, D_loss=0.0000, G_loss=13.0618]\n",
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [14:23<00:00,  1.17s/it, D_loss=0.0000, G_loss=13.4370]\n",
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [15:01<00:00,  1.22s/it, D_loss=0.0000, G_loss=14.2681]\n",
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [2:12:17<00:00, 10.71s/it, D_loss=0.0000, G_loss=14.4038]     \n",
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [1:40:09<00:00,  8.11s/it, D_loss=0.0000, G_loss=14.6584]      \n",
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 741/741 [2:49:30<00:00, 13.73s/it, D_loss=0.0000, G_loss=15.1950]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # ‚úÖ progress bar\n",
    "\n",
    "from models.generator import UNetGenerator\n",
    "from models.discriminator import PatchDiscriminator\n",
    "from utils import sample_random_age\n",
    "\n",
    "# =====================\n",
    "# üîß Hyperparameters\n",
    "# =====================\n",
    "num_epochs = 10  # ‚ö° Fewer epochs for faster testing\n",
    "batch_size = 32  # ‚ö° Larger batch for faster convergence\n",
    "learning_rate = 0.0002\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = torch.cuda.amp.GradScaler()  # ‚úÖ Mixed precision scaler\n",
    "\n",
    "# =====================\n",
    "# üß† Dataset\n",
    "# =====================\n",
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.files = glob.glob(os.path.join(root, \"*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.files[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        try:\n",
    "            age = int(os.path.basename(img_path).split(\"_\")[0])\n",
    "        except:\n",
    "            age = 0\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(age, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "# =====================\n",
    "# üñºÔ∏è Transforms\n",
    "# =====================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),   # ‚ö° smaller for faster compute\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# üì¶ DataLoader\n",
    "# =====================\n",
    "dataset = UTKFaceDataset(root=\"data/utkface\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "print(f\"Loaded {len(dataset)} images for training!\")\n",
    "\n",
    "# =====================\n",
    "# ‚öôÔ∏è Models\n",
    "# =====================\n",
    "generator = UNetGenerator().to(device)\n",
    "discriminator = PatchDiscriminator().to(device)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# =====================\n",
    "# üöÄ Training Loop\n",
    "# =====================\n",
    "for epoch in range(num_epochs):\n",
    "    progress = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for real_faces, real_ages in progress:\n",
    "        real_faces, real_ages = real_faces.to(device), real_ages.to(device)\n",
    "        target_ages = sample_random_age(real_ages.size(0)).to(device)\n",
    "\n",
    "        # ======================\n",
    "        # Train Discriminator\n",
    "        # ======================\n",
    "        with torch.cuda.amp.autocast():  # ‚úÖ mixed precision\n",
    "            fake_faces = generator(real_faces, target_ages).detach()\n",
    "            d_real = discriminator(real_faces, real_ages)\n",
    "            d_fake = discriminator(fake_faces, target_ages)\n",
    "            d_loss = -(torch.mean(torch.log(d_real + 1e-8) + torch.log(1 - d_fake + 1e-8)))\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        scaler.scale(d_loss).backward()\n",
    "        scaler.step(optimizer_D)\n",
    "\n",
    "        # ======================\n",
    "        # Train Generator\n",
    "        # ======================\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake_faces = generator(real_faces, target_ages)\n",
    "            d_fake = discriminator(fake_faces, target_ages)\n",
    "            g_loss = -torch.mean(torch.log(d_fake + 1e-8))\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        scaler.scale(g_loss).backward()\n",
    "        scaler.step(optimizer_G)\n",
    "        scaler.update()\n",
    "\n",
    "        progress.set_postfix({\"D_loss\": f\"{d_loss.item():.4f}\", \"G_loss\": f\"{g_loss.item():.4f}\"})\n",
    "\n",
    "print(\"‚úÖ Training completed successfully!\")\n",
    "\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "torch.save(generator.state_dict(), \"saved_models/generator_fast.pth\")\n",
    "torch.save(discriminator.state_dict(), \"saved_models/discriminator_fast.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d41d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23708 images for training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/2964 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m real_faces, real_ages \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[0;32m     81\u001b[0m     real_faces \u001b[38;5;241m=\u001b[39m real_faces\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 82\u001b[0m     real_ages \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_age\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_ages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     83\u001b[0m     target_ages \u001b[38;5;241m=\u001b[39m normalize_age(sample_random_age(batch_size))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# ===== Generator Forward =====\u001b[39;00m\n",
      "File \u001b[1;32mc:\\RRRRRRResume Projectttttttt\\AI Based Human Face Aging and Rejuvenation (GAN(cGAN), U-Net gen, PathGAN dis)\\AI HUMAN FACE AGING\\utils.py:25\u001b[0m, in \u001b[0;36mnormalize_age\u001b[1;34m(age, max_age)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_age\u001b[39m(age, max_age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_age\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "from models.generator import UNetGenerator\n",
    "from models.discriminator import PatchDiscriminator\n",
    "from utils import normalize_age, sample_random_age  # make sure normalize_age() is in utils.py\n",
    "\n",
    "# =====================\n",
    "# üîß Hyperparameters\n",
    "# =====================\n",
    "num_epochs = 30\n",
    "batch_size = 8\n",
    "learning_rate = 0.0002\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# =====================\n",
    "# üß† Custom UTKFace Dataset\n",
    "# =====================\n",
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.files = glob.glob(os.path.join(root, \"*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.files[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        try:\n",
    "            age = int(os.path.basename(img_path).split(\"_\")[0])\n",
    "        except:\n",
    "            age = 0\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(age, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# üñºÔ∏è Transforms\n",
    "# =====================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# üì¶ Load Dataset\n",
    "# =====================\n",
    "dataset = UTKFaceDataset(root=\"data/utkface\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Loaded {len(dataset)} images for training!\")\n",
    "\n",
    "# =====================\n",
    "# ‚öôÔ∏è Initialize Models\n",
    "# =====================\n",
    "generator = UNetGenerator().to(device)\n",
    "discriminator = PatchDiscriminator().to(device)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "l1_loss = nn.L1Loss()  # For extra sharpness\n",
    "\n",
    "# =====================\n",
    "# üöÄ Training Loop\n",
    "# =====================\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for real_faces, real_ages in progress_bar:\n",
    "        real_faces = real_faces.to(device)\n",
    "        real_ages = normalize_age(real_ages).to(device)\n",
    "        target_ages = normalize_age(sample_random_age(batch_size)).to(device)\n",
    "\n",
    "        # ===== Generator Forward =====\n",
    "        fake_faces = generator(real_faces, target_ages)\n",
    "\n",
    "        # ===== Train Discriminator =====\n",
    "        real_preds = discriminator(real_faces, real_ages)\n",
    "        fake_preds = discriminator(fake_faces.detach(), target_ages)\n",
    "\n",
    "        d_loss_real = criterion(real_preds, torch.ones_like(real_preds))\n",
    "        d_loss_fake = criterion(fake_preds, torch.zeros_like(fake_preds))\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ===== Train Generator =====\n",
    "        fake_preds = discriminator(fake_faces, target_ages)\n",
    "        g_adv_loss = criterion(fake_preds, torch.ones_like(fake_preds))\n",
    "        g_l1 = l1_loss(fake_faces, real_faces) * 100  # pixel sharpness boost\n",
    "        g_loss = g_adv_loss + g_l1\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        progress_bar.set_postfix(D_loss=d_loss.item(), G_loss=g_loss.item())\n",
    "\n",
    "    # ‚úÖ Save checkpoint every few epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        os.makedirs(\"saved_models\", exist_ok=True)\n",
    "        torch.save(generator.state_dict(), f\"saved_models/gen_epoch_{epoch+1}.pth\")\n",
    "\n",
    "print(\"‚úÖ Training completed successfully! Model saved in 'saved_models/' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
